{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3a1823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadarDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, S=7, B=2, C=20):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "        self.image_paths = sorted(glob.glob(os.path.join(image_dir, '*.png')))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label_path = os.path.join(self.label_dir, os.path.basename(image_path).replace('.png', '.txt'))\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        image = self.transform(image)\n",
    "\n",
    "        label_matrix = torch.zeros((self.S, self.S, self.B * 5 + self.C))\n",
    "\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    cls, x, y, w, h = map(float, line.strip().split())\n",
    "                    i = min(int(self.S * y), self.S - 1)\n",
    "                    j = min(int(self.S * x), self.S - 1)\n",
    "                    x_cell, y_cell = self.S * x - j, self.S * y - i\n",
    "\n",
    "                    if label_matrix[i, j, 4] == 0:\n",
    "                        label_matrix[i, j, 0:5] = torch.tensor([x_cell, y_cell, w, h, 1])\n",
    "                        label_matrix[i, j, 5 + int(cls)] = 1\n",
    "\n",
    "        return image, label_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv1(nn.Module):\n",
    "    def __init__(self, S=7, B=2, C=20):\n",
    "        super(YOLOv1, self).__init__()\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3), nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(192, 128, kernel_size=1), nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=1), nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 8 * 8, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(4096, S * S * (C + B * 5))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x.view(-1, self.S, self.S, self.B * 5 + self.C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7262d511",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloLoss(nn.Module):\n",
    "    def __init__(self, S=7, B=2, C=20, lambda_coord=5, lambda_noobj=0.5):\n",
    "        super(YoloLoss, self).__init__()\n",
    "        self.mse = nn.MSELoss(reduction='sum')\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "\n",
    "    def forward(self, predictions, target):\n",
    "        obj_mask = target[..., 4] == 1\n",
    "        noobj_mask = target[..., 4] == 0\n",
    "\n",
    "        # Localization loss\n",
    "        box_pred = predictions[obj_mask][..., 0:4]\n",
    "        box_target = target[obj_mask][..., 0:4]\n",
    "        coord_loss = self.lambda_coord * self.mse(box_pred, box_target)\n",
    "\n",
    "        # Confidence loss (object and no-object)\n",
    "        conf_pred = predictions[..., 4]\n",
    "        conf_target = target[..., 4]\n",
    "        obj_conf_loss = self.mse(conf_pred[obj_mask], conf_target[obj_mask])\n",
    "        noobj_conf_loss = self.lambda_noobj * self.mse(conf_pred[noobj_mask], conf_target[noobj_mask])\n",
    "\n",
    "        # Classification loss\n",
    "        class_pred = predictions[obj_mask][..., 5:]\n",
    "        class_target = target[obj_mask][..., 5:]\n",
    "        class_loss = self.mse(class_pred, class_target)\n",
    "\n",
    "        return coord_loss + obj_conf_loss + noobj_conf_loss + class_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[0]+box1[2], box2[0]+box2[2])\n",
    "    y2 = min(box1[1]+box1[3], box2[1]+box2[3])\n",
    "\n",
    "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    box1_area = box1[2] * box1[3]\n",
    "    box2_area = box2[2] * box2[3]\n",
    "    union = box1_area + box2_area - inter_area\n",
    "    return inter_area / union if union else 0\n",
    "\n",
    "def nms(boxes, iou_thresh=0.5):\n",
    "    boxes = sorted(boxes, key=lambda x: x[1], reverse=True)\n",
    "    keep = []\n",
    "    while boxes:\n",
    "        best = boxes.pop(0)\n",
    "        keep.append(best)\n",
    "        boxes = [b for b in boxes if iou(b[2:], best[2:]) < iou_thresh]\n",
    "    return keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_predictions(preds, S=7, B=2, C=20, conf_thresh=0.2):\n",
    "    batch_size = preds.shape[0]\n",
    "    decoded = []\n",
    "    for b in range(batch_size):\n",
    "        boxes = []\n",
    "        pred = preds[b]\n",
    "        for i in range(S):\n",
    "            for j in range(S):\n",
    "                for b_idx in range(B):\n",
    "                    offset = b_idx * 5\n",
    "                    conf = pred[i, j, offset + 4]\n",
    "                    if conf > conf_thresh:\n",
    "                        x = (pred[i, j, offset + 0] + j) / S\n",
    "                        y = (pred[i, j, offset + 1] + i) / S\n",
    "                        w = pred[i, j, offset + 2]\n",
    "                        h = pred[i, j, offset + 3]\n",
    "                        cls = torch.argmax(pred[i, j, B * 5:]).item()\n",
    "                        boxes.append([cls, conf.item(), x, y, w, h])\n",
    "        decoded.append(nms(boxes))\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa064bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device, class_names, image_dir, label_dir):\n",
    "    model.eval()\n",
    "    all_preds = {}\n",
    "    start = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (imgs, _) in enumerate(tqdm(loader, desc='Evaluating')):\n",
    "            imgs = imgs.to(device)\n",
    "            preds = model(imgs).cpu()\n",
    "            decoded = decode_predictions(preds)\n",
    "            for j in range(imgs.size(0)):\n",
    "                global_idx = i * loader.batch_size + j\n",
    "                all_preds[global_idx] = decoded[j]\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"\\nâœ… Inference Speed: {len(loader.dataset)/(end-start):.2f} FPS\")\n",
    "\n",
    "    # Ground truth to COCO format\n",
    "    coco_images, coco_annotations, ann_id = [], [], 1\n",
    "    for img_id, img_file in enumerate(sorted(glob.glob(os.path.join(image_dir, '*.png')))):\n",
    "        file_name = os.path.basename(img_file)\n",
    "        coco_images.append({\"id\": img_id, \"file_name\": file_name, \"width\": 128, \"height\": 128})\n",
    "\n",
    "        label_path = os.path.join(label_dir, file_name.replace('.png', '.txt'))\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    cls, x, y, w, h = map(float, line.strip().split())\n",
    "                    x_min = (x - w/2) * 128\n",
    "                    y_min = (y - h/2) * 128\n",
    "                    coco_annotations.append({\n",
    "                        \"id\": ann_id,\n",
    "                        \"image_id\": img_id,\n",
    "                        \"category_id\": int(cls),\n",
    "                        \"bbox\": [x_min, y_min, w*128, h*128],\n",
    "                        \"area\": w*128*h*128,\n",
    "                        \"iscrowd\": 0\n",
    "                    })\n",
    "                    ann_id += 1\n",
    "\n",
    "    gt_json = {\"images\": coco_images, \"annotations\": coco_annotations,\n",
    "               \"categories\": [{\"id\": i, \"name\": n} for i, n in enumerate(class_names)]}\n",
    "    with open(\"ground_truth.json\", 'w') as f: json.dump(gt_json, f)\n",
    "\n",
    "    # Predictions to COCO format\n",
    "    pred_json = []\n",
    "    for img_id, preds in all_preds.items():\n",
    "        for pred in preds:\n",
    "            cls, conf, x, y, w, h = pred\n",
    "            x_min = (x - w / 2) * 128\n",
    "            y_min = (y - h / 2) * 128\n",
    "            pred_json.append({\n",
    "                \"image_id\": img_id,\n",
    "                \"category_id\": int(cls),\n",
    "                \"bbox\": [x_min, y_min, w*128, h*128],\n",
    "                \"score\": float(conf)\n",
    "            })\n",
    "    with open(\"predictions.json\", 'w') as f: json.dump(pred_json, f)\n",
    "\n",
    "    if len(pred_json) == 0:\n",
    "        print(\"No predictions above threshold. Skipping mAP evaluation.\")\n",
    "        return\n",
    "\n",
    "    # COCO mAP evaluation\n",
    "    coco_gt = COCO(\"ground_truth.json\")\n",
    "    coco_dt = coco_gt.loadRes(\"predictions.json\")\n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d265a70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    class_names = [f\"Class{i}\" for i in range(20)]\n",
    "    image_dir = \"path/to/images\"\n",
    "    label_dir = \"path/to/labels\"\n",
    "\n",
    "    dataset = RadarDataset(image_dir, label_dir, C=len(class_names))\n",
    "    loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    model = YOLOv1(C=len(class_names)).to(device)\n",
    "    criterion = YoloLoss(C=len(class_names))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        loop = tqdm(loader, desc=f\"Epoch {epoch+1}\")\n",
    "        total_loss = 0\n",
    "\n",
    "        for imgs, labels in loop:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            preds = model(imgs)\n",
    "            loss = criterion(preds, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        print(f\"Epoch {epoch+1} avg loss: {total_loss/len(loader):.4f}\")\n",
    "\n",
    "    evaluate(model, loader, device, class_names, image_dir, label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c73b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
